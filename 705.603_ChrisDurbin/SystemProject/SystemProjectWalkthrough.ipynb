{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4385dc9b",
   "metadata": {},
   "source": [
    "# Platform for Reinforcement Learning Experiments\n",
    "## Chris Durbin system project\n",
    "In this notebook I will walk through my system project. I will provide a rationale for my project, a high level overview for what the project does and its components, then delve into examples of how to use the project. Finally I will wrap up the notebook adding more details based on the rubric for the assignment and how everything fits in with the 6Ds framework.\n",
    "\n",
    "## Rationale\n",
    "I chose this specific project because I see reinforcement learning showing a lot of promise in the pursuit of general intelligence, and I want to understand it well, especially the latest advances in the research. I've wanted to try out the OpenAI Gym for the last few years, and I've known I want a good way to tweak and test experiments without losing track of what I tweaked and what worked the best. So I decided on setting up a platform for running reinforcement algorithm experiments with an initial focus on using the OpenAI Gym environments, but with a path towards incorporating any environment.\n",
    "\n",
    "## Overview\n",
    "\n",
    "Since my project fits into the Platform as a Service (PaaS) model there is a lot that you can do, but not a concrete single demo of \"the project\". The best way to show what in can do is to walk through a few use case examples of how one might utilize the PaaS for different scenarios. Ideally the environment is robust enough that it can handle scenarios I have not even considered.\n",
    "\n",
    "I used the rubric as well as the 6Ds framework as a guide to decide what to demo and how to best describe the project. In addition to having them guide the use cases, I also addressed them directly at the end of this notebook. I've also provided links so you can directly jump to those sections if you want more details on the platform before running the examples.\n",
    "\n",
    "For the platform I am combining several open source projects:\n",
    "\n",
    "[OpenAI Gym](https://www.gymlibrary.dev/) for the environments, [CleanRL](https://docs.cleanrl.dev/) for the reinforcement algorithms implementing the agents, and [Weights and Biases](https://docs.wandb.ai/) for tracking experiments. I'll go into more detail on these later on in the notebook, but figured it's best to jump right in with an example to show them in action.\n",
    "\n",
    "## Table of Contents\n",
    "* [Using the PaaS](#using-paas)\n",
    "* [Use cases](#use-case-1)\n",
    "    - [Use case 1: Compare different RL algorithms](#use-case-1)\n",
    "    - [Use case 2: Stochasticity](#use-case-2) Effect of randomly ignoring chosen actions on learning performance.\n",
    "    - [Use case 3: Resuming training of checkpointed model](#use-case-3)\n",
    "* [Docker setup](#docker-setup)\n",
    "* [Experiment tracking](#experiment-tracking)\n",
    "* [Rubric](#rubric)\n",
    "* [6Ds Framework](#6ds-framework)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a5f3d6",
   "metadata": {},
   "source": [
    "<a id=\"using-paas\"></a>\n",
    "## Using the PaaS\n",
    "\n",
    "I will now show three use cases to give an idea on how to use the platform. Each of these use cases trains an agent against the CartPole environment. I picked the CartPole environment for the demos because it trains quickly and is easy to see how well it is performing by watching the saved videos. For the CartPole environment the goal is to move the cart in a way to keep the pole balanced without falling over. The maximum score for an episode is 200 meaning the pole did not fall over in 200 timesteps.\n",
    "\n",
    "<img src=\"images/CartPole2.png\" width=\"300\" />\n",
    "\n",
    "Note that the platform can be run using Docker and the provided image or locally on the host. The experiment tracking with Weights and Biases can be self hosted or using the cloud hosted version. I have tested with each of the permutations. More instructions can be found in the Docker repository, but my recommendation would be to run locally and with Weights and Biases configured to use the cloud hosted version at https://wandb.ai/. You will need to create an account and then login.\n",
    "\n",
    "First make sure to install of the necessary libraries.\n",
    "\n",
    "**WARNING** On the first install this can take several minutes especially on a slow network connection due to the multiple GB PyTorch dependency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07fc2b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gym==0.23.1\n",
      "  Downloading gym-0.23.1.tar.gz (626 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m626.2/626.2 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting numpy==1.23.4\n",
      "  Downloading numpy-1.23.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pygame==2.1.0\n",
      "  Downloading pygame-2.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torch==1.13.0\n",
      "  Downloading torch-1.13.0-cp38-cp38-manylinux1_x86_64.whl (890.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m890.2/890.2 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tensorboard==2.11.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 5)) (2.11.0)\n",
      "Collecting wandb==0.13.5\n",
      "  Downloading wandb-0.13.5-py2.py3-none-any.whl (1.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting poetry==1.2.2\n",
      "  Downloading poetry-1.2.2-py3-none-any.whl (212 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.4/212.4 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.8/dist-packages (from gym==0.23.1->-r requirements.txt (line 1)) (0.0.7)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /root/.local/lib/python3.8/site-packages (from gym==0.23.1->-r requirements.txt (line 1)) (2.1.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.10.0 in /usr/local/lib/python3.8/dist-packages (from gym==0.23.1->-r requirements.txt (line 1)) (5.0.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.13.0->-r requirements.txt (line 4)) (4.4.0)\n",
      "Collecting nvidia-cuda-runtime-cu11==11.7.99\n",
      "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
      "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96\n",
      "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66\n",
      "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard==2.11.0->-r requirements.txt (line 5)) (1.33.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard==2.11.0->-r requirements.txt (line 5)) (2.28.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard==2.11.0->-r requirements.txt (line 5)) (3.4.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard==2.11.0->-r requirements.txt (line 5)) (0.4.4)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard==2.11.0->-r requirements.txt (line 5)) (65.5.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard==2.11.0->-r requirements.txt (line 5)) (1.8.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard==2.11.0->-r requirements.txt (line 5)) (2.2.2)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.8/dist-packages (from tensorboard==2.11.0->-r requirements.txt (line 5)) (1.3.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.8/dist-packages (from tensorboard==2.11.0->-r requirements.txt (line 5)) (0.36.2)\n",
      "Requirement already satisfied: protobuf<4,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorboard==2.11.0->-r requirements.txt (line 5)) (3.17.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard==2.11.0->-r requirements.txt (line 5)) (0.6.1)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard==2.11.0->-r requirements.txt (line 5)) (1.34.1)\n",
      "Collecting pathtools\n",
      "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.8/dist-packages (from wandb==0.13.5->-r requirements.txt (line 6)) (1.16.0)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from wandb==0.13.5->-r requirements.txt (line 6)) (6.0)\n",
      "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.8/dist-packages (from wandb==0.13.5->-r requirements.txt (line 6)) (2.3)\n",
      "Collecting sentry-sdk>=1.0.0\n",
      "  Downloading sentry_sdk-1.12.0-py2.py3-none-any.whl (173 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.0/174.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting shortuuid>=0.5.0\n",
      "  Downloading shortuuid-1.0.11-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb==0.13.5->-r requirements.txt (line 6)) (3.1.27)\n",
      "Requirement already satisfied: setproctitle in /usr/local/lib/python3.8/dist-packages (from wandb==0.13.5->-r requirements.txt (line 6)) (1.3.2)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.8/dist-packages (from wandb==0.13.5->-r requirements.txt (line 6)) (8.1.3)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb==0.13.5->-r requirements.txt (line 6)) (5.9.3)\n",
      "Collecting docker-pycreds>=0.4.0\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Collecting dulwich<0.21.0,>=0.20.46\n",
      "  Downloading dulwich-0.20.50-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (502 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m502.2/502.2 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting html5lib<2.0,>=1.0\n",
      "  Downloading html5lib-1.1-py2.py3-none-any.whl (112 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.2/112.2 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting keyring>=21.2.0\n",
      "  Downloading keyring-23.11.0-py3-none-any.whl (36 kB)\n",
      "Collecting cleo<2.0.0,>=1.0.0a5\n",
      "  Downloading cleo-1.0.0a5-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pexpect<5.0.0,>=4.7.0 in /usr/local/lib/python3.8/dist-packages (from poetry==1.2.2->-r requirements.txt (line 7)) (4.7.0)\n",
      "Collecting poetry-plugin-export<2.0.0,>=1.1.2\n",
      "  Downloading poetry_plugin_export-1.2.0-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: urllib3<2.0.0,>=1.26.0 in /usr/local/lib/python3.8/dist-packages (from poetry==1.2.2->-r requirements.txt (line 7)) (1.26.12)\n",
      "Collecting virtualenv!=20.4.5,!=20.4.6,>=20.4.3\n",
      "  Downloading virtualenv-20.17.1-py3-none-any.whl (8.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting platformdirs<3.0.0,>=2.5.2\n",
      "  Downloading platformdirs-2.6.0-py3-none-any.whl (14 kB)\n",
      "Collecting importlib-metadata>=4.10.0\n",
      "  Downloading importlib_metadata-4.13.0-py3-none-any.whl (23 kB)\n",
      "Collecting crashtest<0.4.0,>=0.3.0\n",
      "  Downloading crashtest-0.3.1-py3-none-any.whl (7.0 kB)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.10.0 in /usr/local/lib/python3.8/dist-packages (from poetry==1.2.2->-r requirements.txt (line 7)) (4.16.0)\n",
      "Collecting pkginfo<2.0,>=1.5\n",
      "  Downloading pkginfo-1.9.2-py3-none-any.whl (26 kB)\n",
      "Collecting cachy<0.4.0,>=0.3.0\n",
      "  Downloading cachy-0.3.0-py2.py3-none-any.whl (20 kB)\n",
      "Collecting poetry-core==1.3.2\n",
      "  Downloading poetry_core-1.3.2-py3-none-any.whl (531 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m531.3/531.3 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests-toolbelt<0.10.0,>=0.9.1 in /root/.local/lib/python3.8/site-packages (from poetry==1.2.2->-r requirements.txt (line 7)) (0.9.1)\n",
      "Collecting tomlkit!=0.11.2,!=0.11.3,<1.0.0,>=0.11.1\n",
      "  Downloading tomlkit-0.11.6-py3-none-any.whl (35 kB)\n",
      "Collecting cachecontrol[filecache]<0.13.0,>=0.12.9\n",
      "  Downloading CacheControl-0.12.11-py2.py3-none-any.whl (21 kB)\n",
      "Collecting shellingham<2.0,>=1.5\n",
      "  Downloading shellingham-1.5.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Requirement already satisfied: packaging>=20.4 in /usr/local/lib/python3.8/dist-packages (from poetry==1.2.2->-r requirements.txt (line 7)) (21.3)\n",
      "Requirement already satisfied: msgpack>=0.5.2 in /usr/local/lib/python3.8/dist-packages (from cachecontrol[filecache]<0.13.0,>=0.12.9->poetry==1.2.2->-r requirements.txt (line 7)) (1.0.3)\n",
      "Requirement already satisfied: lockfile>=0.9 in /usr/local/lib/python3.8/dist-packages (from cachecontrol[filecache]<0.13.0,>=0.12.9->poetry==1.2.2->-r requirements.txt (line 7)) (0.12.2)\n",
      "Collecting pylev<2.0.0,>=1.3.0\n",
      "  Downloading pylev-1.4.0-py2.py3-none-any.whl (6.1 kB)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.8/dist-packages (from GitPython>=1.0.0->wandb==0.13.5->-r requirements.txt (line 6)) (4.0.9)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard==2.11.0->-r requirements.txt (line 5)) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard==2.11.0->-r requirements.txt (line 5)) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard==2.11.0->-r requirements.txt (line 5)) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard==2.11.0->-r requirements.txt (line 5)) (1.3.0)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.8/dist-packages (from html5lib<2.0,>=1.0->poetry==1.2.2->-r requirements.txt (line 7)) (0.5.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.10.0->gym==0.23.1->-r requirements.txt (line 1)) (3.10.0)\n",
      "Requirement already satisfied: pkgutil-resolve-name>=1.3.10 in /usr/local/lib/python3.8/dist-packages (from jsonschema<5.0.0,>=4.10.0->poetry==1.2.2->-r requirements.txt (line 7)) (1.3.10)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema<5.0.0,>=4.10.0->poetry==1.2.2->-r requirements.txt (line 7)) (0.18.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema<5.0.0,>=4.10.0->poetry==1.2.2->-r requirements.txt (line 7)) (22.1.0)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema<5.0.0,>=4.10.0->poetry==1.2.2->-r requirements.txt (line 7)) (5.10.0)\n",
      "Collecting jeepney>=0.4.2\n",
      "  Downloading jeepney-0.8.0-py3-none-any.whl (48 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.4/48.4 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting SecretStorage>=3.2\n",
      "  Downloading SecretStorage-3.3.3-py3-none-any.whl (15 kB)\n",
      "Collecting jaraco.classes\n",
      "  Downloading jaraco.classes-3.2.3-py3-none-any.whl (6.0 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.4->poetry==1.2.2->-r requirements.txt (line 7)) (3.0.9)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect<5.0.0,>=4.7.0->poetry==1.2.2->-r requirements.txt (line 7)) (0.7.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard==2.11.0->-r requirements.txt (line 5)) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard==2.11.0->-r requirements.txt (line 5)) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard==2.11.0->-r requirements.txt (line 5)) (3.4)\n",
      "Requirement already satisfied: filelock<4,>=3.4.1 in /usr/local/lib/python3.8/dist-packages (from virtualenv!=20.4.5,!=20.4.6,>=20.4.3->poetry==1.2.2->-r requirements.txt (line 7)) (3.8.2)\n",
      "Collecting distlib<1,>=0.3.6\n",
      "  Downloading distlib-0.3.6-py2.py3-none-any.whl (468 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.5/468.5 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.8/dist-packages (from werkzeug>=1.0.1->tensorboard==2.11.0->-r requirements.txt (line 5)) (2.1.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.8/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb==0.13.5->-r requirements.txt (line 6)) (5.0.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard==2.11.0->-r requirements.txt (line 5)) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard==2.11.0->-r requirements.txt (line 5)) (3.1.1)\n",
      "Requirement already satisfied: cryptography>=2.0 in /usr/local/lib/python3.8/dist-packages (from SecretStorage>=3.2->keyring>=21.2.0->poetry==1.2.2->-r requirements.txt (line 7)) (38.0.1)\n",
      "Collecting more-itertools\n",
      "  Downloading more_itertools-9.0.0-py3-none-any.whl (52 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.8/52.8 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.8/dist-packages (from cryptography>=2.0->SecretStorage>=3.2->keyring>=21.2.0->poetry==1.2.2->-r requirements.txt (line 7)) (1.15.1)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.12->cryptography>=2.0->SecretStorage>=3.2->keyring>=21.2.0->poetry==1.2.2->-r requirements.txt (line 7)) (2.21)\n",
      "Building wheels for collected packages: gym, pathtools\n",
      "  Building wheel for gym (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gym: filename=gym-0.23.1-py3-none-any.whl size=701357 sha256=025cf6892262d130c2324286a248e7f8f4f72e57017cf0dab6bf68194cf9b81a\n",
      "  Stored in directory: /root/.cache/pip/wheels/d3/56/dd/a5bc7d77ebab2ec36c6e0ca163c7cf342c0d53e6f9a7910ff3\n",
      "  Building wheel for pathtools (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=d8e7dad584936da4cf71c4c921c6df1b730de38ed3716f6b668ce77e89b3df92\n",
      "  Stored in directory: /root/.cache/pip/wheels/4d/33/74/7c0903053e955973d5dc3d21857a29b3f8c0806ad0b05c32a1\n",
      "Successfully built gym pathtools\n",
      "Installing collected packages: pylev, pathtools, distlib, tomlkit, shortuuid, shellingham, sentry-sdk, pygame, poetry-core, platformdirs, pkginfo, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, numpy, more-itertools, jeepney, importlib-metadata, html5lib, dulwich, docker-pycreds, crashtest, cachy, virtualenv, nvidia-cudnn-cu11, jaraco.classes, gym, cleo, cachecontrol, wandb, torch, SecretStorage, keyring, poetry-plugin-export, poetry\n",
      "  Attempting uninstall: pygame\n",
      "    Found existing installation: pygame 2.1.2\n",
      "    Uninstalling pygame-2.1.2:\n",
      "      Successfully uninstalled pygame-2.1.2\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.23.5\n",
      "    Uninstalling numpy-1.23.5:\n",
      "      Successfully uninstalled numpy-1.23.5\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 5.0.0\n",
      "    Uninstalling importlib-metadata-5.0.0:\n",
      "      Successfully uninstalled importlib-metadata-5.0.0\n",
      "  Attempting uninstall: gym\n",
      "    Found existing installation: gym 0.25.1\n",
      "    Uninstalling gym-0.25.1:\n",
      "      Successfully uninstalled gym-0.25.1\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.12.0\n",
      "    Uninstalling torch-1.12.0:\n",
      "      Successfully uninstalled torch-1.12.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchvision 0.13.0 requires torch==1.12.0, but you have torch 1.13.0 which is incompatible.\n",
      "sagemaker 2.108.0 requires attrs<22,>=20.3.0, but you have attrs 22.1.0 which is incompatible.\n",
      "numba 0.55.0 requires numpy<1.22,>=1.18, but you have numpy 1.23.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed SecretStorage-3.3.3 cachecontrol-0.12.11 cachy-0.3.0 cleo-1.0.0a5 crashtest-0.3.1 distlib-0.3.6 docker-pycreds-0.4.0 dulwich-0.20.50 gym-0.23.1 html5lib-1.1 importlib-metadata-4.13.0 jaraco.classes-3.2.3 jeepney-0.8.0 keyring-23.11.0 more-itertools-9.0.0 numpy-1.23.4 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 pathtools-0.1.2 pkginfo-1.9.2 platformdirs-2.6.0 poetry-1.2.2 poetry-core-1.3.2 poetry-plugin-export-1.2.0 pygame-2.1.0 pylev-1.4.0 sentry-sdk-1.12.0 shellingham-1.5.0 shortuuid-1.0.11 tomlkit-0.11.6 torch-1.13.0 virtualenv-20.17.1 wandb-0.13.5\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30330800",
   "metadata": {},
   "source": [
    "#### Log in to wandb\n",
    "You will need to run `wandb login` once from a terminal and follow the instructions to configure your API key. After that you will remain logged in and will not need to do that again.\n",
    "\n",
    "In the cell below I am just verifying that I am logged in with my account, the key setup needs to be done outside of Jupyter if you get any kind of interactive prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eab40076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjhebeler\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "!wandb login"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c340040",
   "metadata": {},
   "source": [
    "<a id=\"use-case-1\"></a>\n",
    "### Use case 1 - Benchmark multiple reinforcement learning algorithms to compare training time and performance for each algorithm\n",
    "\n",
    "#### Kicking off the first run using the PPO algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9ec4722-e387-43fb-b2d5-b9703e7633e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"SDL_VIDEODRIVER\"] = \"dummy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5236d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-17 13:16:46.192834: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-17 13:16:46.866931: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.8/dist-packages/cv2/../../lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2022-12-17 13:16:46.866991: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.8/dist-packages/cv2/../../lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2022-12-17 13:16:46.867001: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjhebeler\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.13.7 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/rapids/notebooks/workspace/Hopkins/EN.705.603.82_Fall2022/finalProjects/705.603_ChrisDurbin/SystemProject/wandb/run-20221217_131647-22p8ifkt\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mCartPole-v0__ppo__1__1671283005\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/jhebeler/cart_pole_algo_compare\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/jhebeler/cart_pole_algo_compare/runs/22p8ifkt\u001b[0m\n",
      "2022-12-17 13:16:54.034813: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/usr/local/lib/python3.8/dist-packages/gym/core.py:172: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed) instead.\u001b[0m\n",
      "  deprecation(\n",
      "2022-12-17 13:16:54.773025: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.8/dist-packages/cv2/../../lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2022-12-17 13:16:54.773090: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.8/dist-packages/cv2/../../lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2022-12-17 13:16:54.773099: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/usr/local/lib/python3.8/dist-packages/gym/wrappers/monitoring/video_recorder.py:115: DeprecationWarning: \u001b[33mWARN: `env.metadata[\"video.frames_per_second\"] is marked as deprecated and will be replaced with `env.metadata[\"render_fps\"]` see https://github.com/openai/gym/pull/2654 for more details\u001b[0m\n",
      "  logger.deprecation(\n",
      "/usr/local/lib/python3.8/dist-packages/gym/wrappers/monitoring/video_recorder.py:421: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if distutils.version.LooseVersion(\n",
      "global_step=36, episodic_return=9.0\n",
      "global_step=52, episodic_return=13.0\n",
      "global_step=100, episodic_return=25.0\n",
      "global_step=112, episodic_return=19.0\n",
      "global_step=128, episodic_return=32.0\n",
      "global_step=144, episodic_return=11.0\n",
      "global_step=152, episodic_return=13.0\n",
      "global_step=176, episodic_return=12.0\n",
      "global_step=196, episodic_return=11.0\n",
      "global_step=228, episodic_return=13.0\n",
      "global_step=260, episodic_return=16.0\n",
      "global_step=296, episodic_return=46.0\n",
      "global_step=300, episodic_return=39.0\n",
      "global_step=312, episodic_return=13.0\n",
      "global_step=360, episodic_return=15.0\n",
      "global_step=388, episodic_return=40.0\n",
      "global_step=400, episodic_return=22.0\n",
      "global_step=408, episodic_return=28.0\n",
      "global_step=440, episodic_return=13.0\n",
      "global_step=460, episodic_return=15.0\n",
      "global_step=484, episodic_return=31.0\n",
      "global_step=500, episodic_return=23.0\n",
      "SPS: 513\n",
      "global_step=10244, episodic_return=138.0\n",
      "global_step=10308, episodic_return=54.0\n",
      "global_step=10388, episodic_return=20.0\n",
      "global_step=10436, episodic_return=165.0\n",
      "global_step=10508, episodic_return=166.0\n",
      "global_step=10548, episodic_return=76.0\n",
      "global_step=10736, episodic_return=75.0\n",
      "SPS: 1873\n",
      "global_step=20596, episodic_return=146.0\n",
      "global_step=20808, episodic_return=200.0\n",
      "global_step=20920, episodic_return=165.0\n",
      "global_step=20984, episodic_return=200.0\n",
      "SPS: 2219\n",
      "global_step=30888, episodic_return=106.0\n",
      "global_step=31164, episodic_return=200.0\n",
      "SPS: 2351\n",
      "global_step=41192, episodic_return=197.0\n",
      "global_step=41240, episodic_return=152.0\n",
      "global_step=41260, episodic_return=158.0\n",
      "SPS: 2442\n",
      "global_step=49384, episodic_return=200.0\n",
      "global_step=49500, episodic_return=166.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                charts/SPS ▁▂▃▄▅▅▆▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    charts/episodic_length ▁▂▁▂▁▁▁▂▂▁▁▃▂▂▁▃▂▂▂▄█▆▇██▆▆██▅███▅▄█████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    charts/episodic_return ▁▂▁▂▁▁▁▂▂▁▁▃▂▂▁▃▂▂▂▄█▆▇██▆▆██▅███▅▄█████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      charts/learning_rate ███▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               global_step ▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▃▃▃▃▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          losses/approx_kl ▃▅▆▅▁▅▂█▃▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           losses/clipfrac ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            losses/entropy ██▇▆▅▄▃▄▄▃▃▄▃▃▄▃▃▂▂▂▂▂▂▂▂▃▃▂▁▃▂▂▃▁▂▂▁▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: losses/explained_variance ▁▂▂▂▁▂▂▄▄▄▆▅▆▅▇▇▇▅▆▅▆█▆▅▄▄▆▄▅█▆▇▄▅▄▃▃▂▃▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      losses/old_approx_kl ▁▃█▇▃▅█▂▄▄▅▃▃▄▃▄▄▃▄▃▅▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        losses/policy_loss ▆▄▂▁█▂▇█▄▇▆▇▇▇▅▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         losses/value_loss ▁▁▂▂▄▅▅▃▇▇██▆▇█▇▆▅▇▅▆▅▅▅▅▄▄▅▅▅▄▅▅▅▅▆▅▄▄▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                charts/SPS 2395.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    charts/episodic_length 166.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    charts/episodic_return 166.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      charts/learning_rate 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               global_step 49664\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          losses/approx_kl 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           losses/clipfrac 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            losses/entropy 0.55955\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: losses/explained_variance 0.07527\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      losses/old_approx_kl 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        losses/policy_loss -0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         losses/value_loss 64.49356\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mCartPole-v0__ppo__1__1671283005\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/jhebeler/cart_pole_algo_compare/runs/22p8ifkt\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 6 media file(s), 0 artifact file(s) and 2 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20221217_131647-22p8ifkt/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python code/ppo.py \\\n",
    "    --env-id CartPole-v0 \\\n",
    "    --total-timesteps 50000 \\\n",
    "    --wandb-project-name cart_pole_algo_compare \\\n",
    "    --track \\\n",
    "    --capture-video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8dff0d0",
   "metadata": {},
   "source": [
    "#### Kicking off the second run using the Deep Q Learning algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45d0dd53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-17 13:28:48.596334: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-17 13:28:49.267405: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.8/dist-packages/cv2/../../lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2022-12-17 13:28:49.267469: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.8/dist-packages/cv2/../../lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2022-12-17 13:28:49.267479: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjhebeler\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.13.7 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/rapids/notebooks/workspace/Hopkins/EN.705.603.82_Fall2022/finalProjects/705.603_ChrisDurbin/SystemProject/wandb/run-20221217_132850-7gxgx354\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mCartPole-v0__dqn__1__1671283727\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/jhebeler/cart_pole_algo_compare\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/jhebeler/cart_pole_algo_compare/runs/7gxgx354\u001b[0m\n",
      "2022-12-17 13:28:56.915677: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-17 13:28:57.673929: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.8/dist-packages/cv2/../../lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2022-12-17 13:28:57.673990: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.8/dist-packages/cv2/../../lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2022-12-17 13:28:57.674001: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Traceback (most recent call last):\n",
      "  File \"code/dqn.py\", line 119, in <module>\n",
      "    obs = envs.reset()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/gym/vector/vector_env.py\", line 62, in reset\n",
      "    return self.reset_wait()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/gym/vector/sync_vector_env.py\", line 69, in reset_wait\n",
      "    observation = env.reset()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/gym/wrappers/record_video.py\", line 58, in reset\n",
      "    self.start_video_recorder()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/gym/wrappers/record_video.py\", line 75, in start_video_recorder\n",
      "    self.video_recorder.capture_frame()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/gym/wrappers/monitoring/video_recorder.py\", line 132, in capture_frame\n",
      "    frame = self.env.render(mode=render_mode)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/gym/core.py\", line 295, in render\n",
      "    return self.env.render(mode, **kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/gym/core.py\", line 295, in render\n",
      "    return self.env.render(mode, **kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/gym/envs/classic_control/cartpole.py\", line 179, in render\n",
      "    from gym.envs.classic_control import rendering\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/gym/envs/classic_control/rendering.py\", line 27, in <module>\n",
      "    from pyglet.gl import *\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pyglet/gl/__init__.py\", line 243, in <module>\n",
      "    import pyglet.window\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pyglet/window/__init__.py\", line 1897, in <module>\n",
      "    gl._create_shadow_window()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pyglet/gl/__init__.py\", line 220, in _create_shadow_window\n",
      "    _shadow_window = Window(width=1, height=1, visible=False)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pyglet/window/xlib/__init__.py\", line 173, in __init__\n",
      "    super(XlibWindow, self).__init__(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pyglet/window/__init__.py\", line 585, in __init__\n",
      "    display = pyglet.canvas.get_display()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pyglet/canvas/__init__.py\", line 94, in get_display\n",
      "    return Display()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pyglet/canvas/xlib.py\", line 123, in __init__\n",
      "    raise NoSuchDisplayException('Cannot connect to \"%s\"' % name)\n",
      "pyglet.canvas.xlib.NoSuchDisplayException: Cannot connect to \"None\"\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[31m(failed 1).\u001b[0m Press Control-C to abort syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mCartPole-v0__dqn__1__1671283727\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/jhebeler/cart_pole_algo_compare/runs/7gxgx354\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20221217_132850-7gxgx354/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python code/dqn.py \\\n",
    "    --seed 1 \\\n",
    "    --env-id CartPole-v0 \\\n",
    "    --total-timesteps 50000 \\\n",
    "    --wandb-project-name cart_pole_algo_compare \\\n",
    "    --track \\\n",
    "    --capture-video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27439179",
   "metadata": {},
   "source": [
    "#### Kicking off the third and final run using the C51 algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13465472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/cdurbin/opt/anaconda3/envs/rl-gym/lib/python3.9/site-packages/torch/utils/tensorboard/__init__.py:4: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not hasattr(tensorboard, \"__version__\") or LooseVersion(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mchrisatumd\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.13.6 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/cdurbin/JHU/CreatingAIEnabledSystems/dockershare/SystemProject/wandb/run-20221210_225829-cmqg5igt\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mCartPole-v0__c51__1__1670731108\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/chrisatumd/cart_pole_algo_compare\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/chrisatumd/cart_pole_algo_compare/runs/cmqg5igt\u001b[0m\n",
      "global_step=1200, episodic_return=22.0\n",
      "global_step=2000, episodic_return=13.0\n",
      "global_step=2200, episodic_return=22.0\n",
      "global_step=3700, episodic_return=18.0\n",
      "global_step=7900, episodic_return=24.0\n",
      "global_step=12100, episodic_return=11.0\n",
      "global_step=13500, episodic_return=10.0\n",
      "global_step=14800, episodic_return=12.0\n",
      "SPS: 1863\n",
      "global_step=16200, episodic_return=19.0\n",
      "global_step=16800, episodic_return=20.0\n",
      "global_step=17300, episodic_return=40.0\n",
      "SPS: 1418\n",
      "global_step=20200, episodic_return=28.0\n",
      "SPS: 1232\n",
      "SPS: 1133\n",
      "global_step=34400, episodic_return=167.0\n",
      "SPS: 1074\n",
      "SPS: 1052\n",
      "SPS: 1048\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             charts/SPS █▄▃▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: charts/episodic_length ▁▁▂▁▁▁▂▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▃▂▃█▇█▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: charts/episodic_return ▁▁▂▁▁▁▂▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▃▂▃█▇█▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         charts/epsilon ███▇▇▇▇▇▆▆▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▂▂▂▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            global_step ▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▃▃▃▃▃▃▃▃▃▃▃▃▄▄▄▄▄▅▅▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            losses/loss ▇█▇▇▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        losses/q_values ▁▂▃▅▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             charts/SPS 1048.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: charts/episodic_length 177.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: charts/episodic_return 177.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         charts/epsilon 0.05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            global_step 49998\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            losses/loss 3.49327\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        losses/q_values 38.60122\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mCartPole-v0__c51__1__1670731108\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/chrisatumd/cart_pole_algo_compare/runs/cmqg5igt\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 11 media file(s), 0 artifact file(s) and 2 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20221210_225829-cmqg5igt/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python code/c51.py \\\n",
    "    --seed 1 \\\n",
    "    --env-id CartPole-v0 \\\n",
    "    --total-timesteps 50000 \\\n",
    "    --wandb-project-name cart_pole_algo_compare \\\n",
    "    --track \\\n",
    "    --capture-video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658ef3d9",
   "metadata": {},
   "source": [
    "### Comparing performance\n",
    "I then bring up the three runs in Weights and Biases which when self hosted is running on http://localhost:8080  or if cloud hosted is at https://wandb.ai/, and look at the charts and tables for the project I created called cart_pole_algo_compare. From looking at the charts I can see that PPO takes the least time to run 50,000 total steps and improves performance quickly though it seems to have more variance in episode length (my performance metric) than the other two algorithms. It looks like there is not a slam dunk winner for any of the algorithms. I would continue to test the algorithms with different parameters to try to choose the best one for my case. Note that I was running 50,000 total timesteps for each task which ended up running a different number of episodes so the runs for each do not cover the entire X axis (only the slowest one to improve training will which in this scenario was the C51 algorithm).\n",
    "\n",
    "<p float=\"left\">\n",
    "  <img src=\"images/AlgorithmPerformanceLearningCurve.png\", width=\"300\"/>\n",
    "  <img src=\"images/AlgorithmComparisonTimes.png\", width=\"300\"/>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7aa7c74",
   "metadata": {},
   "source": [
    "<a id=\"use-case-2\"></a>\n",
    "### Use case 2 - Test impact of chosen action replaced at random some percent of the time\n",
    "For this experiment I want to see the affect on the performance of my reinforcement learning algorithm if a chosen action for a step is replaced by a random action. I added support for a flag --ignore-action that takes a value between 0 and 1 and ignores the chosen action that percentage of the time (0.15 means 15 percent). I tested this with a few different configurations (0, 0.15, 0.35, and 0.70). In the notebook I am just demoing 0 and 0.35. I am using the PPO algorithm for the rest of the tests since it is the fastest one to train.\n",
    "\n",
    "#### Baseline with chosen action always used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e177a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mchrisatumd\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.13.6 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/cdurbin/JHU/CreatingAIEnabledSystems/dockershare/SystemProject/wandb/run-20221210_225934-xbms5sry\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mCartPole-v0__CartPoleBaseline__1__1670731173\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/chrisatumd/cart_pole_random_actions\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/chrisatumd/cart_pole_random_actions/runs/xbms5sry\u001b[0m\n",
      "/Users/cdurbin/opt/anaconda3/envs/rl-gym/lib/python3.9/site-packages/wandb/sdk/lib/import_hooks.py:246: DeprecationWarning: Deprecated since Python 3.4. Use importlib.util.find_spec() instead.\n",
      "  loader = importlib.find_loader(fullname, path)\n",
      "/Users/cdurbin/opt/anaconda3/envs/rl-gym/lib/python3.9/site-packages/gym/core.py:172: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed) instead.\u001b[0m\n",
      "  deprecation(\n",
      "/Users/cdurbin/opt/anaconda3/envs/rl-gym/lib/python3.9/site-packages/gym/wrappers/monitoring/video_recorder.py:115: DeprecationWarning: \u001b[33mWARN: `env.metadata[\"video.frames_per_second\"] is marked as deprecated and will be replaced with `env.metadata[\"render_fps\"]` see https://github.com/openai/gym/pull/2654 for more details\u001b[0m\n",
      "  logger.deprecation(\n",
      "/Users/cdurbin/opt/anaconda3/envs/rl-gym/lib/python3.9/site-packages/gym/wrappers/monitoring/video_recorder.py:421: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if distutils.version.LooseVersion(\n",
      "global_step=52, episodic_return=13.0\n",
      "global_step=68, episodic_return=17.0\n",
      "global_step=76, episodic_return=19.0\n",
      "global_step=128, episodic_return=15.0\n",
      "global_step=144, episodic_return=17.0\n",
      "/Users/cdurbin/opt/anaconda3/envs/rl-gym/lib/python3.9/site-packages/gym/wrappers/monitoring/video_recorder.py:115: DeprecationWarning: \u001b[33mWARN: `env.metadata[\"video.frames_per_second\"] is marked as deprecated and will be replaced with `env.metadata[\"render_fps\"]` see https://github.com/openai/gym/pull/2654 for more details\u001b[0m\n",
      "  logger.deprecation(\n",
      "/Users/cdurbin/opt/anaconda3/envs/rl-gym/lib/python3.9/site-packages/gym/wrappers/monitoring/video_recorder.py:421: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if distutils.version.LooseVersion(\n",
      "global_step=200, episodic_return=50.0\n",
      "global_step=224, episodic_return=24.0\n",
      "global_step=248, episodic_return=26.0\n",
      "global_step=284, episodic_return=21.0\n",
      "global_step=296, episodic_return=12.0\n",
      "global_step=312, episodic_return=28.0\n",
      "global_step=324, episodic_return=25.0\n",
      "global_step=376, episodic_return=23.0\n",
      "global_step=384, episodic_return=18.0\n",
      "global_step=428, episodic_return=11.0\n",
      "global_step=436, episodic_return=35.0\n",
      "global_step=448, episodic_return=18.0\n",
      "global_step=476, episodic_return=12.0\n",
      "global_step=488, episodic_return=41.0\n",
      "SPS: 495\n",
      "/Users/cdurbin/opt/anaconda3/envs/rl-gym/lib/python3.9/site-packages/gym/wrappers/monitoring/video_recorder.py:115: DeprecationWarning: \u001b[33mWARN: `env.metadata[\"video.frames_per_second\"] is marked as deprecated and will be replaced with `env.metadata[\"render_fps\"]` see https://github.com/openai/gym/pull/2654 for more details\u001b[0m\n",
      "  logger.deprecation(\n",
      "/Users/cdurbin/opt/anaconda3/envs/rl-gym/lib/python3.9/site-packages/gym/wrappers/monitoring/video_recorder.py:421: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if distutils.version.LooseVersion(\n",
      "/Users/cdurbin/opt/anaconda3/envs/rl-gym/lib/python3.9/site-packages/gym/wrappers/monitoring/video_recorder.py:115: DeprecationWarning: \u001b[33mWARN: `env.metadata[\"video.frames_per_second\"] is marked as deprecated and will be replaced with `env.metadata[\"render_fps\"]` see https://github.com/openai/gym/pull/2654 for more details\u001b[0m\n",
      "  logger.deprecation(\n",
      "/Users/cdurbin/opt/anaconda3/envs/rl-gym/lib/python3.9/site-packages/gym/wrappers/monitoring/video_recorder.py:421: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if distutils.version.LooseVersion(\n",
      "/Users/cdurbin/opt/anaconda3/envs/rl-gym/lib/python3.9/site-packages/gym/wrappers/monitoring/video_recorder.py:115: DeprecationWarning: \u001b[33mWARN: `env.metadata[\"video.frames_per_second\"] is marked as deprecated and will be replaced with `env.metadata[\"render_fps\"]` see https://github.com/openai/gym/pull/2654 for more details\u001b[0m\n",
      "  logger.deprecation(\n",
      "/Users/cdurbin/opt/anaconda3/envs/rl-gym/lib/python3.9/site-packages/gym/wrappers/monitoring/video_recorder.py:421: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if distutils.version.LooseVersion(\n",
      "global_step=10504, episodic_return=97.0\n",
      "global_step=10636, episodic_return=131.0\n",
      "global_step=10676, episodic_return=116.0\n",
      "global_step=10684, episodic_return=124.0\n",
      "global_step=10712, episodic_return=52.0\n",
      "SPS: 2736\n",
      "global_step=20548, episodic_return=151.0\n",
      "global_step=20640, episodic_return=200.0\n",
      "global_step=20748, episodic_return=174.0\n",
      "global_step=20916, episodic_return=152.0\n",
      "SPS: 3308\n",
      "global_step=30832, episodic_return=178.0\n",
      "global_step=30908, episodic_return=92.0\n",
      "global_step=31144, episodic_return=190.0\n",
      "global_step=31188, episodic_return=121.0\n",
      "SPS: 3583\n",
      "global_step=41032, episodic_return=200.0\n",
      "global_step=41452, episodic_return=200.0\n",
      "SPS: 3712\n",
      "/Users/cdurbin/opt/anaconda3/envs/rl-gym/lib/python3.9/site-packages/gym/wrappers/monitoring/video_recorder.py:115: DeprecationWarning: \u001b[33mWARN: `env.metadata[\"video.frames_per_second\"] is marked as deprecated and will be replaced with `env.metadata[\"render_fps\"]` see https://github.com/openai/gym/pull/2654 for more details\u001b[0m\n",
      "  logger.deprecation(\n",
      "/Users/cdurbin/opt/anaconda3/envs/rl-gym/lib/python3.9/site-packages/gym/wrappers/monitoring/video_recorder.py:421: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if distutils.version.LooseVersion(\n",
      "global_step=49232, episodic_return=107.0\n",
      "global_step=49592, episodic_return=159.0\n",
      "global_step=49604, episodic_return=127.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                charts/SPS ▁▂▃▄▄▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇██████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    charts/episodic_length ▂▂▂▁▁▁▂▂▁▁▂▁▂▂▂▂▂▅▃▃▅█▅▂█▆▇██▇█▄▃▅▆▅██▅▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    charts/episodic_return ▂▂▂▁▁▁▂▂▁▁▂▁▂▂▂▂▂▅▃▃▅█▅▂█▆▇██▇█▄▃▅▆▅██▅▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      charts/learning_rate ███▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               global_step ▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▇▇▇▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          losses/approx_kl ▇▄█▁▅▂▃▄▃▅▁▇▂▂▂▂▁▅▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           losses/clipfrac ▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            losses/entropy ██▇▇▆▅▄▄▄▃▅▃▂▄▂▄▄▂▃▂▁▂▃▃▃▃▃▃▃▃▁▃▂▃▂▃▂▂▂▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: losses/explained_variance ▂▃▃▂▂▄▃▁▆▇█▂▅▃▄▆▄▅▆▂▅▆▅▃▄▄▃▂▄▅▆▆▆▃▂▄▇▄▅▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      losses/old_approx_kl ▄▅▇▃▁▃▆▃▅█▄▃▇▅▆▅▅▆▄▅▆▄▄▄▄▅▄▄▄▄▄▄▄▄▄▄▄▄▄▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        losses/policy_loss ▆▄▁█▅▇▆▆▆▇▆▆▇█▆▆▆▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         losses/value_loss ▁▂▄▄▂▃▃▄▆▅█▅▃▄▆▅▇▆▅▆▅▅▅▄▅▅▅▅▃▄▄▄▄▄▄▄▄▄▄▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                charts/SPS 3689.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    charts/episodic_length 127.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    charts/episodic_return 127.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      charts/learning_rate 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               global_step 49664\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          losses/approx_kl 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           losses/clipfrac 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            losses/entropy 0.58366\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: losses/explained_variance 0.06722\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      losses/old_approx_kl 2e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        losses/policy_loss -2e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         losses/value_loss 61.77739\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mCartPole-v0__CartPoleBaseline__1__1670731173\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/chrisatumd/cart_pole_random_actions/runs/xbms5sry\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 6 media file(s), 0 artifact file(s) and 3 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20221210_225934-xbms5sry/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python code/ppo.py \\\n",
    "    --seed 1 \\\n",
    "    --exp-name CartPoleBaseline \\\n",
    "    --env-id CartPole-v0 \\\n",
    "    --total-timesteps 50000 \\\n",
    "    --wandb-project-name cart_pole_random_actions \\\n",
    "    --track \\\n",
    "    --capture-video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3104e836",
   "metadata": {},
   "source": [
    "#### Experiment with random action used 35% of the time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcb6ba6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mchrisatumd\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.13.6 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/cdurbin/JHU/CreatingAIEnabledSystems/dockershare/SystemProject/wandb/run-20221210_230004-36pzvr1y\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mCartPole-v0__CartPoleRandom35__1__1670731203\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/chrisatumd/cart_pole_random_actions\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/chrisatumd/cart_pole_random_actions/runs/36pzvr1y\u001b[0m\n",
      "/Users/cdurbin/opt/anaconda3/envs/rl-gym/lib/python3.9/site-packages/wandb/sdk/lib/import_hooks.py:246: DeprecationWarning: Deprecated since Python 3.4. Use importlib.util.find_spec() instead.\n",
      "  loader = importlib.find_loader(fullname, path)\n",
      "/Users/cdurbin/opt/anaconda3/envs/rl-gym/lib/python3.9/site-packages/gym/core.py:172: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed) instead.\u001b[0m\n",
      "  deprecation(\n",
      "/Users/cdurbin/opt/anaconda3/envs/rl-gym/lib/python3.9/site-packages/gym/wrappers/monitoring/video_recorder.py:115: DeprecationWarning: \u001b[33mWARN: `env.metadata[\"video.frames_per_second\"] is marked as deprecated and will be replaced with `env.metadata[\"render_fps\"]` see https://github.com/openai/gym/pull/2654 for more details\u001b[0m\n",
      "  logger.deprecation(\n",
      "/Users/cdurbin/opt/anaconda3/envs/rl-gym/lib/python3.9/site-packages/gym/wrappers/monitoring/video_recorder.py:421: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if distutils.version.LooseVersion(\n",
      "global_step=52, episodic_return=13.0\n",
      "global_step=68, episodic_return=17.0\n",
      "global_step=76, episodic_return=19.0\n",
      "global_step=128, episodic_return=15.0\n",
      "global_step=144, episodic_return=17.0\n",
      "/Users/cdurbin/opt/anaconda3/envs/rl-gym/lib/python3.9/site-packages/gym/wrappers/monitoring/video_recorder.py:115: DeprecationWarning: \u001b[33mWARN: `env.metadata[\"video.frames_per_second\"] is marked as deprecated and will be replaced with `env.metadata[\"render_fps\"]` see https://github.com/openai/gym/pull/2654 for more details\u001b[0m\n",
      "  logger.deprecation(\n",
      "/Users/cdurbin/opt/anaconda3/envs/rl-gym/lib/python3.9/site-packages/gym/wrappers/monitoring/video_recorder.py:421: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if distutils.version.LooseVersion(\n",
      "global_step=200, episodic_return=50.0\n",
      "global_step=224, episodic_return=24.0\n",
      "global_step=248, episodic_return=26.0\n",
      "global_step=284, episodic_return=21.0\n",
      "global_step=296, episodic_return=12.0\n",
      "global_step=312, episodic_return=28.0\n",
      "global_step=324, episodic_return=25.0\n",
      "global_step=376, episodic_return=23.0\n",
      "global_step=384, episodic_return=18.0\n",
      "global_step=428, episodic_return=11.0\n",
      "global_step=436, episodic_return=35.0\n",
      "global_step=448, episodic_return=18.0\n",
      "global_step=476, episodic_return=12.0\n",
      "global_step=488, episodic_return=41.0\n",
      "SPS: 497\n",
      "/Users/cdurbin/opt/anaconda3/envs/rl-gym/lib/python3.9/site-packages/gym/wrappers/monitoring/video_recorder.py:115: DeprecationWarning: \u001b[33mWARN: `env.metadata[\"video.frames_per_second\"] is marked as deprecated and will be replaced with `env.metadata[\"render_fps\"]` see https://github.com/openai/gym/pull/2654 for more details\u001b[0m\n",
      "  logger.deprecation(\n",
      "/Users/cdurbin/opt/anaconda3/envs/rl-gym/lib/python3.9/site-packages/gym/wrappers/monitoring/video_recorder.py:421: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if distutils.version.LooseVersion(\n",
      "/Users/cdurbin/opt/anaconda3/envs/rl-gym/lib/python3.9/site-packages/gym/wrappers/monitoring/video_recorder.py:115: DeprecationWarning: \u001b[33mWARN: `env.metadata[\"video.frames_per_second\"] is marked as deprecated and will be replaced with `env.metadata[\"render_fps\"]` see https://github.com/openai/gym/pull/2654 for more details\u001b[0m\n",
      "  logger.deprecation(\n",
      "/Users/cdurbin/opt/anaconda3/envs/rl-gym/lib/python3.9/site-packages/gym/wrappers/monitoring/video_recorder.py:421: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if distutils.version.LooseVersion(\n",
      "/Users/cdurbin/opt/anaconda3/envs/rl-gym/lib/python3.9/site-packages/gym/wrappers/monitoring/video_recorder.py:115: DeprecationWarning: \u001b[33mWARN: `env.metadata[\"video.frames_per_second\"] is marked as deprecated and will be replaced with `env.metadata[\"render_fps\"]` see https://github.com/openai/gym/pull/2654 for more details\u001b[0m\n",
      "  logger.deprecation(\n",
      "/Users/cdurbin/opt/anaconda3/envs/rl-gym/lib/python3.9/site-packages/gym/wrappers/monitoring/video_recorder.py:421: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if distutils.version.LooseVersion(\n",
      "global_step=10296, episodic_return=19.0\n",
      "global_step=10304, episodic_return=20.0\n",
      "global_step=10328, episodic_return=24.0\n",
      "global_step=10384, episodic_return=22.0\n",
      "global_step=10412, episodic_return=21.0\n",
      "global_step=10452, episodic_return=17.0\n",
      "global_step=10472, episodic_return=36.0\n",
      "global_step=10528, episodic_return=14.0\n",
      "global_step=10600, episodic_return=18.0\n",
      "global_step=10628, episodic_return=39.0\n",
      "global_step=10644, episodic_return=58.0\n",
      "global_step=10660, episodic_return=52.0\n",
      "global_step=10668, episodic_return=17.0\n",
      "global_step=10712, episodic_return=21.0\n",
      "global_step=10748, episodic_return=9.0\n",
      "SPS: 2679\n",
      "/Users/cdurbin/opt/anaconda3/envs/rl-gym/lib/python3.9/site-packages/gym/wrappers/monitoring/video_recorder.py:115: DeprecationWarning: \u001b[33mWARN: `env.metadata[\"video.frames_per_second\"] is marked as deprecated and will be replaced with `env.metadata[\"render_fps\"]` see https://github.com/openai/gym/pull/2654 for more details\u001b[0m\n",
      "  logger.deprecation(\n",
      "/Users/cdurbin/opt/anaconda3/envs/rl-gym/lib/python3.9/site-packages/gym/wrappers/monitoring/video_recorder.py:421: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if distutils.version.LooseVersion(\n",
      "global_step=20504, episodic_return=29.0\n",
      "global_step=20572, episodic_return=71.0\n",
      "global_step=20588, episodic_return=21.0\n",
      "global_step=20600, episodic_return=46.0\n",
      "global_step=20624, episodic_return=41.0\n",
      "global_step=20700, episodic_return=32.0\n",
      "global_step=20712, episodic_return=31.0\n",
      "global_step=20724, episodic_return=31.0\n",
      "global_step=20788, episodic_return=19.0\n",
      "global_step=20828, episodic_return=10.0\n",
      "global_step=20836, episodic_return=53.0\n",
      "global_step=20844, episodic_return=30.0\n",
      "global_step=20944, episodic_return=25.0\n",
      "global_step=20948, episodic_return=30.0\n",
      "SPS: 3165\n",
      "/Users/cdurbin/opt/anaconda3/envs/rl-gym/lib/python3.9/site-packages/gym/wrappers/monitoring/video_recorder.py:115: DeprecationWarning: \u001b[33mWARN: `env.metadata[\"video.frames_per_second\"] is marked as deprecated and will be replaced with `env.metadata[\"render_fps\"]` see https://github.com/openai/gym/pull/2654 for more details\u001b[0m\n",
      "  logger.deprecation(\n",
      "/Users/cdurbin/opt/anaconda3/envs/rl-gym/lib/python3.9/site-packages/gym/wrappers/monitoring/video_recorder.py:421: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if distutils.version.LooseVersion(\n",
      "global_step=30760, episodic_return=61.0\n",
      "global_step=30800, episodic_return=23.0\n",
      "global_step=30848, episodic_return=22.0\n",
      "global_step=30872, episodic_return=67.0\n",
      "global_step=30920, episodic_return=18.0\n",
      "global_step=30952, episodic_return=20.0\n",
      "global_step=30976, episodic_return=77.0\n",
      "global_step=31040, episodic_return=60.0\n",
      "global_step=31052, episodic_return=25.0\n",
      "global_step=31092, episodic_return=10.0\n",
      "global_step=31156, episodic_return=26.0\n",
      "global_step=31168, episodic_return=19.0\n",
      "global_step=31212, episodic_return=43.0\n",
      "global_step=31224, episodic_return=17.0\n",
      "global_step=31232, episodic_return=48.0\n",
      "SPS: 3400\n",
      "global_step=40976, episodic_return=69.0\n",
      "global_step=40988, episodic_return=59.0\n",
      "global_step=41064, episodic_return=50.0\n",
      "global_step=41080, episodic_return=26.0\n",
      "global_step=41176, episodic_return=47.0\n",
      "global_step=41180, episodic_return=29.0\n",
      "global_step=41232, episodic_return=73.0\n",
      "global_step=41288, episodic_return=52.0\n",
      "global_step=41292, episodic_return=28.0\n",
      "global_step=41320, episodic_return=36.0\n",
      "global_step=41380, episodic_return=37.0\n",
      "SPS: 3529\n",
      "/Users/cdurbin/opt/anaconda3/envs/rl-gym/lib/python3.9/site-packages/gym/wrappers/monitoring/video_recorder.py:115: DeprecationWarning: \u001b[33mWARN: `env.metadata[\"video.frames_per_second\"] is marked as deprecated and will be replaced with `env.metadata[\"render_fps\"]` see https://github.com/openai/gym/pull/2654 for more details\u001b[0m\n",
      "  logger.deprecation(\n",
      "/Users/cdurbin/opt/anaconda3/envs/rl-gym/lib/python3.9/site-packages/gym/wrappers/monitoring/video_recorder.py:421: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if distutils.version.LooseVersion(\n",
      "global_step=49168, episodic_return=18.0\n",
      "global_step=49284, episodic_return=41.0\n",
      "global_step=49336, episodic_return=42.0\n",
      "global_step=49348, episodic_return=82.0\n",
      "global_step=49444, episodic_return=27.0\n",
      "global_step=49476, episodic_return=48.0\n",
      "global_step=49568, episodic_return=114.0\n",
      "global_step=49576, episodic_return=25.0\n",
      "global_step=49608, episodic_return=41.0\n",
      "global_step=49612, episodic_return=34.0\n",
      "global_step=49656, episodic_return=22.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                charts/SPS ▁▂▃▄▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    charts/episodic_length ▄▃▁▁▂▆▂▁▂▂▂▄▅▁▇▂▂▁▁▅▄▆▁▄▂▁▄▂▄▆▄▂▅█▃▆▂▆▁▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    charts/episodic_return ▄▃▁▁▂▆▂▁▂▂▂▄▅▁▇▂▂▁▁▅▄▆▁▄▂▁▄▂▄▆▄▂▅█▃▆▂▆▁▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      charts/learning_rate ███▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               global_step ▁▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          losses/approx_kl ▁▁▁▃▁▁▁▂▁▁▁▁▁▄▅▁▁▄▁▁▁▆▁▆▁▁█▁▁▁█▁▁▁▁▅▁▇▇▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           losses/clipfrac ▁▁▁▄▃▄▂▄▂▂▂▃▄▄▃▄▅▃▃▆▃▅▄▂▄▄▆█▄▂▅▅▂▆▄▄▄▄▇▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            losses/entropy ███▆▇▇▇▇██▇▇▆▅▄▄▄▅▄▃▄▃▄▂▂▂▂▂▂▂▂▃▁▂▁▃▂▂▂▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: losses/explained_variance ▁▃▃▄▄▆▃▅▃▅▄▄▆▆▃▅▄█▅▅▃▅▅▇▄▃▃▆▄▅▅▅▆▂▅▆▂▃▂▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      losses/old_approx_kl ▅▅▅▅▅▅▅▅▅▅▅▅▅▃▅▅▅█▅▅▅▇▅▂▅▅▁▅▅▅▂▅▅▅▅▄▅▄▅▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        losses/policy_loss ▁▁▁▂▁▁▁▂▁▁▁▁▁▃▃▁▁▃▁▁▁▄▁▅▁▁▅▁▁▁█▁▁▁▁▃▁▆▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         losses/value_loss ▅▆▇█▆▇▇▅▄▂▃▄▃▁▃▃▁█▄▁▃▅▄▃▄▄▅▆▅▆▂▇▃▅▅▄▄▆▆▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                charts/SPS 3571.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    charts/episodic_length 22.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    charts/episodic_return 22.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      charts/learning_rate 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               global_step 49664\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          losses/approx_kl 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           losses/clipfrac 0.13916\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            losses/entropy 0.6683\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: losses/explained_variance 0.05572\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      losses/old_approx_kl 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        losses/policy_loss 2e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         losses/value_loss 39.93833\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mCartPole-v0__CartPoleRandom35__1__1670731203\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/chrisatumd/cart_pole_random_actions/runs/36pzvr1y\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 8 media file(s), 0 artifact file(s) and 3 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20221210_230004-36pzvr1y/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python code/ppo.py \\\n",
    "    --seed 1 \\\n",
    "    --exp-name CartPoleRandom35 \\\n",
    "    --env-id CartPole-v0 \\\n",
    "    --total-timesteps 50000 \\\n",
    "    --wandb-project-name cart_pole_random_actions \\\n",
    "    --track \\\n",
    "    --capture-video \\\n",
    "    --ignore-action-rate 0.35"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf411fd",
   "metadata": {},
   "source": [
    "**Note**: For the charts below I included two other runs for a total of four runs. You could modify the cells if you wanted to repeat the tests with 0.15 and 0.7 as the values for --ignore-action-rate.\n",
    "\n",
    "The chart showing the performance over time is useful. The four colors are:\n",
    "* Blue - all chosen actions taken\n",
    "* Red - 15% of actions replaced with random action\n",
    "* Purple - 35% of actions replaced with random action\n",
    "* Red - 70% of actions replaced with random action\n",
    "\n",
    "The maximum score for an episode is 200 and each training iteration had 50,000 total steps (so ones that had lower per episode actions taken will have more episodes displayed in the chart). We see that 15% random still achieves the maximum score for many episodes though it takes a little bit longer in training to get there. With 35% random actions the training never achieves the maximum score and at 70% it only achieves a single score over 100. The next steps for this use case would be to run additional experiments with more total steps and different percentages to see at which percentage the training fails to converge to around the maximum score.\n",
    "\n",
    "<img src='images/RandomActionsPerformance.png' width=300/>\n",
    "\n",
    "You can see your own performance in wandb by selecting the cart_pole_random_actions project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d2f396",
   "metadata": {},
   "source": [
    "<a id=\"use-case-3\"></a>\n",
    "### Use case 3 - Checkpoint runs and resume training\n",
    "This was one of the most important use cases for me, and I was excited when I was able to get it working successfully.\n",
    "\n",
    "#### First I'll start a run and tell it to checkpoint the model after every 20 iterations\n",
    "Note the addition of the parameter --checkpoint-frequency=20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7b55a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mchrisatumd\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.13.6 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/cdurbin/JHU/CreatingAIEnabledSystems/dockershare/SystemProject/wandb/run-20221210_230036-2wrh3qoy\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mCartPole-v0__ppo__1__1670731235\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/chrisatumd/cart_pole_checkpoint_and_resume\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/chrisatumd/cart_pole_checkpoint_and_resume/runs/2wrh3qoy\u001b[0m\n",
      "/Users/cdurbin/opt/anaconda3/envs/rl-gym/lib/python3.9/site-packages/wandb/sdk/lib/import_hooks.py:246: DeprecationWarning: Deprecated since Python 3.4. Use importlib.util.find_spec() instead.\n",
      "  loader = importlib.find_loader(fullname, path)\n",
      "/Users/cdurbin/opt/anaconda3/envs/rl-gym/lib/python3.9/site-packages/gym/core.py:172: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed) instead.\u001b[0m\n",
      "  deprecation(\n",
      "/Users/cdurbin/opt/anaconda3/envs/rl-gym/lib/python3.9/site-packages/gym/wrappers/monitoring/video_recorder.py:115: DeprecationWarning: \u001b[33mWARN: `env.metadata[\"video.frames_per_second\"] is marked as deprecated and will be replaced with `env.metadata[\"render_fps\"]` see https://github.com/openai/gym/pull/2654 for more details\u001b[0m\n",
      "  logger.deprecation(\n",
      "/Users/cdurbin/opt/anaconda3/envs/rl-gym/lib/python3.9/site-packages/gym/wrappers/monitoring/video_recorder.py:421: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if distutils.version.LooseVersion(\n",
      "global_step=52, episodic_return=13.0\n",
      "global_step=68, episodic_return=17.0\n",
      "global_step=76, episodic_return=19.0\n",
      "global_step=128, episodic_return=15.0\n",
      "global_step=144, episodic_return=17.0\n",
      "/Users/cdurbin/opt/anaconda3/envs/rl-gym/lib/python3.9/site-packages/gym/wrappers/monitoring/video_recorder.py:115: DeprecationWarning: \u001b[33mWARN: `env.metadata[\"video.frames_per_second\"] is marked as deprecated and will be replaced with `env.metadata[\"render_fps\"]` see https://github.com/openai/gym/pull/2654 for more details\u001b[0m\n",
      "  logger.deprecation(\n",
      "/Users/cdurbin/opt/anaconda3/envs/rl-gym/lib/python3.9/site-packages/gym/wrappers/monitoring/video_recorder.py:421: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if distutils.version.LooseVersion(\n",
      "global_step=200, episodic_return=50.0\n",
      "global_step=224, episodic_return=24.0\n",
      "global_step=248, episodic_return=26.0\n",
      "global_step=284, episodic_return=21.0\n",
      "global_step=296, episodic_return=12.0\n",
      "global_step=312, episodic_return=28.0\n",
      "global_step=324, episodic_return=25.0\n",
      "global_step=376, episodic_return=23.0\n",
      "global_step=384, episodic_return=18.0\n",
      "global_step=428, episodic_return=11.0\n",
      "global_step=436, episodic_return=35.0\n",
      "global_step=448, episodic_return=18.0\n",
      "global_step=476, episodic_return=12.0\n",
      "global_step=488, episodic_return=41.0\n",
      "SPS: 479\n",
      "/Users/cdurbin/opt/anaconda3/envs/rl-gym/lib/python3.9/site-packages/gym/wrappers/monitoring/video_recorder.py:115: DeprecationWarning: \u001b[33mWARN: `env.metadata[\"video.frames_per_second\"] is marked as deprecated and will be replaced with `env.metadata[\"render_fps\"]` see https://github.com/openai/gym/pull/2654 for more details\u001b[0m\n",
      "  logger.deprecation(\n",
      "/Users/cdurbin/opt/anaconda3/envs/rl-gym/lib/python3.9/site-packages/gym/wrappers/monitoring/video_recorder.py:421: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if distutils.version.LooseVersion(\n",
      "/Users/cdurbin/opt/anaconda3/envs/rl-gym/lib/python3.9/site-packages/gym/wrappers/monitoring/video_recorder.py:115: DeprecationWarning: \u001b[33mWARN: `env.metadata[\"video.frames_per_second\"] is marked as deprecated and will be replaced with `env.metadata[\"render_fps\"]` see https://github.com/openai/gym/pull/2654 for more details\u001b[0m\n",
      "  logger.deprecation(\n",
      "/Users/cdurbin/opt/anaconda3/envs/rl-gym/lib/python3.9/site-packages/gym/wrappers/monitoring/video_recorder.py:421: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if distutils.version.LooseVersion(\n",
      "/Users/cdurbin/opt/anaconda3/envs/rl-gym/lib/python3.9/site-packages/gym/wrappers/monitoring/video_recorder.py:115: DeprecationWarning: \u001b[33mWARN: `env.metadata[\"video.frames_per_second\"] is marked as deprecated and will be replaced with `env.metadata[\"render_fps\"]` see https://github.com/openai/gym/pull/2654 for more details\u001b[0m\n",
      "  logger.deprecation(\n",
      "/Users/cdurbin/opt/anaconda3/envs/rl-gym/lib/python3.9/site-packages/gym/wrappers/monitoring/video_recorder.py:421: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if distutils.version.LooseVersion(\n",
      "global_step=9236, episodic_return=25.0\n",
      "global_step=9372, episodic_return=41.0\n",
      "global_step=9384, episodic_return=125.0\n",
      "global_step=9428, episodic_return=48.0\n",
      "global_step=9524, episodic_return=38.0\n",
      "global_step=9532, episodic_return=26.0\n",
      "global_step=9548, episodic_return=41.0\n",
      "global_step=9580, episodic_return=14.0\n",
      "global_step=9676, episodic_return=124.0\n",
      "global_step=9680, episodic_return=37.0\n",
      "Saving model checkpoint\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Saving files without folders. If you want to preserve sub directories pass base_path to wandb.save, i.e. wandb.save(\"/mnt/folder/file.h5\", base_path=\"/mnt\")\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                charts/SPS ▁▂▃▄▅▄▅▅▆▆▆▇▇▇█████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    charts/episodic_length ▁▂▃▁▂▂▁▂▂▂▃▂▁▂▂▃▁▂▂▁▅▄▄▃▄▂▂▃▁▂▂▅█▄▁▄▅▄▃▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    charts/episodic_return ▁▂▃▁▂▂▁▂▂▂▃▂▁▂▂▃▁▂▂▁▅▄▄▃▄▂▂▃▁▂▂▅█▄▁▄▅▄▃▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      charts/learning_rate ██▇▇▆▆▆▅▅▄▄▄▃▃▃▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               global_step ▁▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          losses/approx_kl █▅▃▅▆▇▄▂▃▂▂▃▂▂▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           losses/clipfrac ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            losses/entropy ███▇▇▆▆▅▅▅▄▃▄▃▃▃▁▂▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: losses/explained_variance ▃▃▅▄▅▆▃▂▂▄▆▅▁▅▄█▅▄▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      losses/old_approx_kl ▆▇▇▇▇▆▃▅▁▃▅█▇▆▆▇▆▆▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        losses/policy_loss ▅▄▄▃▁▄▆▆▇▆▅▄▇▅▇▆█▇▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         losses/value_loss ▃▁▄▃▆▅▇▇▆▅▇▆▅▅▆▅█▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                charts/SPS 2265.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    charts/episodic_length 37.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    charts/episodic_return 37.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      charts/learning_rate 1e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               global_step 9728\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          losses/approx_kl 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           losses/clipfrac 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            losses/entropy 0.65836\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: losses/explained_variance -0.01529\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      losses/old_approx_kl 7e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        losses/policy_loss -0.00015\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         losses/value_loss 65.22798\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mCartPole-v0__ppo__1__1670731235\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/chrisatumd/cart_pole_checkpoint_and_resume/runs/2wrh3qoy\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 5 media file(s), 0 artifact file(s) and 3 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20221210_230036-2wrh3qoy/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python code/ppo.py \\\n",
    "    --seed 1 --env-id CartPole-v0 --total-timesteps 10000 \\\n",
    "    --track --capture-video --wandb-project-name cart_pole_checkpoint_and_resume \\\n",
    "    --checkpoint-frequency=20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697af5ac",
   "metadata": {},
   "source": [
    "There are two things to notice from the run:\n",
    "\n",
    "1. We're logging \"Saving model checkpoint\" each time we save the model. This is saving the file locally and then uploading it to W&B.\n",
    "2. The training did not achieve the max score of 200 during the training and so clearly had not converged yet. \n",
    "\n",
    "Rather than start over we'll download the trained model and resume training from that point.\n",
    "\n",
    "**IMPORTANT** For the next test make sure to set the WANDB_RUN_ID below to the value that was printed out as the run identifier when initially running the experiment. For example for my URL: https://wandb.ai/chrisatumd/cart_pole_checkpoint_and_resume/runs/2keuhvm7 the WANDB_RUN_ID to use is 2keuhvm7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a17c2d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_RUN_ID=2keuhvm7\n"
     ]
    }
   ],
   "source": [
    "%env WANDB_RUN_ID 2keuhvm7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044411c0",
   "metadata": {},
   "source": [
    "Now I use the --resume flag combined with setting the environment variable above to indicate which run to resume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "972bff89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mchrisatumd\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.13.6 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/Users/cdurbin/JHU/CreatingAIEnabledSystems/dockershare/SystemProject/wandb/run-20221210_230058-2keuhvm7\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Resuming run \u001b[33mCartPole-v0__ppo__1__1670731257\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/chrisatumd/cart_pole_checkpoint_and_resume\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/chrisatumd/cart_pole_checkpoint_and_resume/runs/2keuhvm7\u001b[0m\n",
      "/Users/cdurbin/opt/anaconda3/envs/rl-gym/lib/python3.9/site-packages/wandb/sdk/lib/import_hooks.py:246: DeprecationWarning: Deprecated since Python 3.4. Use importlib.util.find_spec() instead.\n",
      "  loader = importlib.find_loader(fullname, path)\n",
      "/Users/cdurbin/opt/anaconda3/envs/rl-gym/lib/python3.9/site-packages/gym/core.py:172: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed) instead.\u001b[0m\n",
      "  deprecation(\n",
      "Resuming prior run.\n",
      "Attempting to load file /Users/cdurbin/JHU/CreatingAIEnabledSystems/dockershare/SystemProject/wandb/run-20221210_230058-2keuhvm7/files/agent.pt\n",
      "/Users/cdurbin/opt/anaconda3/envs/rl-gym/lib/python3.9/site-packages/gym/wrappers/monitoring/video_recorder.py:115: DeprecationWarning: \u001b[33mWARN: `env.metadata[\"video.frames_per_second\"] is marked as deprecated and will be replaced with `env.metadata[\"render_fps\"]` see https://github.com/openai/gym/pull/2654 for more details\u001b[0m\n",
      "  logger.deprecation(\n",
      "/Users/cdurbin/opt/anaconda3/envs/rl-gym/lib/python3.9/site-packages/gym/wrappers/monitoring/video_recorder.py:421: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if distutils.version.LooseVersion(\n",
      "global_step=40347, episodic_return=102.0\n",
      "/Users/cdurbin/opt/anaconda3/envs/rl-gym/lib/python3.9/site-packages/gym/wrappers/monitoring/video_recorder.py:115: DeprecationWarning: \u001b[33mWARN: `env.metadata[\"video.frames_per_second\"] is marked as deprecated and will be replaced with `env.metadata[\"render_fps\"]` see https://github.com/openai/gym/pull/2654 for more details\u001b[0m\n",
      "  logger.deprecation(\n",
      "/Users/cdurbin/opt/anaconda3/envs/rl-gym/lib/python3.9/site-packages/gym/wrappers/monitoring/video_recorder.py:421: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if distutils.version.LooseVersion(\n",
      "global_step=40431, episodic_return=123.0\n",
      "SPS: 21116\n",
      "/Users/cdurbin/opt/anaconda3/envs/rl-gym/lib/python3.9/site-packages/gym/wrappers/monitoring/video_recorder.py:115: DeprecationWarning: \u001b[33mWARN: `env.metadata[\"video.frames_per_second\"] is marked as deprecated and will be replaced with `env.metadata[\"render_fps\"]` see https://github.com/openai/gym/pull/2654 for more details\u001b[0m\n",
      "  logger.deprecation(\n",
      "/Users/cdurbin/opt/anaconda3/envs/rl-gym/lib/python3.9/site-packages/gym/wrappers/monitoring/video_recorder.py:421: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if distutils.version.LooseVersion(\n",
      "Saving model checkpoint\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Saving files without folders. If you want to preserve sub directories pass base_path to wandb.save, i.e. wandb.save(\"/mnt/folder/file.h5\", base_path=\"/mnt\")\n",
      "global_step=50347, episodic_return=200.0\n",
      "global_step=50447, episodic_return=200.0\n",
      "SPS: 9402\n",
      "/Users/cdurbin/opt/anaconda3/envs/rl-gym/lib/python3.9/site-packages/gym/wrappers/monitoring/video_recorder.py:115: DeprecationWarning: \u001b[33mWARN: `env.metadata[\"video.frames_per_second\"] is marked as deprecated and will be replaced with `env.metadata[\"render_fps\"]` see https://github.com/openai/gym/pull/2654 for more details\u001b[0m\n",
      "  logger.deprecation(\n",
      "/Users/cdurbin/opt/anaconda3/envs/rl-gym/lib/python3.9/site-packages/gym/wrappers/monitoring/video_recorder.py:421: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if distutils.version.LooseVersion(\n",
      "global_step=59711, episodic_return=200.0\n",
      "global_step=59747, episodic_return=190.0\n",
      "global_step=59767, episodic_return=200.0\n",
      "Saving model checkpoint\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Saving files without folders. If you want to preserve sub directories pass base_path to wandb.save, i.e. wandb.save(\"/mnt/folder/file.h5\", base_path=\"/mnt\")\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                charts/SPS █▇▆▆▆▅▅▅▅▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    charts/episodic_length ▂▆▃█████▇█▆▆█▁▇████▆████▅█▄████▁███▆████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    charts/episodic_return ▂▆▃█████▇█▆▆█▁▇████▆████▅█▄████▁███▆████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      charts/learning_rate ███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               global_step ▁▁▁▁▁▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          losses/approx_kl █▃▂█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           losses/clipfrac ▄▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            losses/entropy ▄▆▅▂▆▃▃▅▆▆▅▃▆▁▄▃▃▃▄█▃▆▅▆▅▄▄▂▄▄▂▅▅▅▂▃▇▃▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: losses/explained_variance ▁▃▄█▂▂▂▇▃▇▆▄▇▅▃▂█▃▄▁▂▂▂▃▂▃▂▁▁▁▂▂▂▃▂▁▂▂▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      losses/old_approx_kl ▄▁▆█▄▅▅▅▅▅▄▅▄▅▅▅▆▅▅▅▅▄▅▅▅▅▅▅▅▅▄▅▅▄▅▅▅▅▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        losses/policy_loss ▇█▆▁▇▇▇▆▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         losses/value_loss ▆▁▄▃▄█▂▅▇▂▂▂▆▃▅▁▂▃▅▃▅▅▅▆▃▄▂▄▇▁▆▄▂▆▆▃▆▅▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                charts/SPS 7012.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    charts/episodic_length 200.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    charts/episodic_return 200.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      charts/learning_rate 1e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               global_step 59907\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          losses/approx_kl 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           losses/clipfrac 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            losses/entropy 0.58512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: losses/explained_variance 0.02492\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      losses/old_approx_kl -1e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        losses/policy_loss -4e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         losses/value_loss 54.99732\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mCartPole-v0__ppo__1__1670731257\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/chrisatumd/cart_pole_checkpoint_and_resume/runs/2keuhvm7\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 3 W&B file(s), 4 media file(s), 0 artifact file(s) and 2 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20221210_230058-2keuhvm7/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python code/ppo.py \\\n",
    "    --seed 1 --env-id CartPole-v0 --total-timesteps 20000 \\\n",
    "    --track --capture-video --wandb-project-name cart_pole_checkpoint_and_resume \\\n",
    "    --checkpoint-frequency=20 \\\n",
    "    --resume"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d0dbd9",
   "metadata": {},
   "source": [
    "I ran the above cell twice for a total of 3 runs. The initial run had 10000 global steps, the second run had 20000 global steps, and the third run 20000 steps. You can see there is a bit of an issue with the metrics tracking the global steps, but I verified that it is successfully resuming the run each time using the previously trained model and each run executes exactly the number of steps I requested. By the end of the third run the episode score reaches the 200 max score frequently.\n",
    "\n",
    "<p float='left'>\n",
    "    <img src='images/ResumedTrainingRun.png', width=300/>\n",
    "    <img src='images/ResumedTrainingRunPerformance.png', width=300/>\n",
    "</p>\n",
    "\n",
    "You can see your own performance in wandb by selecting the cart_pole_checkpoint_and_resume project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9108bd8",
   "metadata": {},
   "source": [
    "<a id=\"docker-setup\"></a>\n",
    "## Docker setup\n",
    "\n",
    "I created a docker container as another way to run the experiments. I also set things up so that I could use a locally hosted Weights and Biases rather than the cloud hosted one used by default. This required some sophisticated setup including setting up a network within docker and giving both the W&B container and my environment container access to that network. In addition my container used docker in docker in order to upload the results to W&B. For the detailed instructions on how to run with the docker container see my [README](https://hub.docker.com/repository/registry-1.docker.io/cdurbin/705.603_chris_durbin/general).\n",
    "\n",
    "I was happy with this setup at first, but by the end I found enough shortcomings that I would not recommend running this way. I included those details in my [findings](#findings) section. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4d8190",
   "metadata": {},
   "source": [
    "<a id=\"experiment-tracking\"></a>\n",
    "## Experiment tracking\n",
    "\n",
    "I showed some of what was being with tracked with the charts in prior cells, but there is much more being captured. Some of what I am capturing and pushing to Weights and Biases includes:\n",
    "\n",
    "* Training Metrics for generating learning curves\n",
    "* The trained model\n",
    "* The source code that was used in order to perform that training run\n",
    "* The duration of the run\n",
    "* Several videos of the agent running in the enviroment at various points in the train run.\n",
    "* The commandline used to kick off the run\n",
    "* Every configuration option passed in to kick off the run\n",
    "* Every hyperparameter setting\n",
    "\n",
    "Here are a few screenshots from my locally hosted Weights and Biases server.\n",
    "\n",
    "<p float='left'>\n",
    "    <img src='images/GeneralViewWandB.png', width=500/>\n",
    "    Overview page\n",
    "    <img src='images/WBTable.png', width=500/>\n",
    "    Metrics and Parameters page\n",
    "    <img src='images/WBFiles.png', width=500/>\n",
    "    Files listing from run\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8fa0ec",
   "metadata": {},
   "source": [
    "## Tensorboard\n",
    "\n",
    "The logging and metrics capture is also compatible with tensorboard. You can bring up tensorboard locally with `tensorboard --logdir runs`. Then you can bring it up locally at http://localhost:6006\n",
    "\n",
    "Here is an example screenshot after running experiments.\n",
    "<p float='left'>\n",
    "    <img src='images/Tensorboard.png', width=500/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e7b830",
   "metadata": {},
   "source": [
    "<a id=\"rubric\"></a>\n",
    "## Rubric\n",
    "Given I could not show everything in a demo I documented how the project addressed each category in the rubric.\n",
    "\n",
    "## Challenge level\n",
    "\n",
    "For this PaaS I am putting together several open source libraries to use in tandem. Throughout my career I have found plumbing together multiple outside projects one of the more difficult tasks in the software development world. In addition with the projects all being relatively new and changing rapidly, it further increases the integration effort.\n",
    "\n",
    "### New technical area\n",
    "The projects I am using are all relatively new projects.\n",
    "\n",
    "* When I started my system project, cleanrl had not yet released version 1.0.0 (they released it twenty days ago). The first commit for the project was in 2020.\n",
    "* WandB has not yet released version 1.0 of their software and their first 0.x release was in late 2019.\n",
    "* The OpenAI gym is slightly more mature with a release date of April 2016, but is still on the leading edge for environments for reinforcement learning.\n",
    "* Tensorboard has also been around for some time with its first release in 2017.\n",
    "\n",
    "I set up the project so that it can run natively on a host, but also have a way to install it using Docker. For the docker setup I needed to use more advanced and challenging features than we needed in the class and more advanced than what I have used in the past. A couple of those features included setting up networks for docker containers to reach one another as well as docker in docker (making docker calls from within a docker container).\n",
    "\n",
    "## Supporting References\n",
    "I heavily used open source projects for putting together my platform. Here are links to some of the open source projects I used and referenced their documentation to set everything up.\n",
    "\n",
    "1. Weights and Biases: [Home page](https://wandb.ai/site), [Documentation](https://docs.wandb.ai/)\n",
    "2. CleanRL: [Repo](https://github.com/vwxyzjn/cleanrl), [Documentation](https://docs.cleanrl.dev/)\n",
    "3. OpenAI Gym: [Repo](https://github.com/openai/gym), [Documentation](https://www.gymlibrary.dev/)\n",
    "4. PyTorch: https://pytorch.org/\n",
    "5. Tensorboard: [Home page](https://www.tensorflow.org/tensorboard), [Repo](https://github.com/tensorflow/tensorboard)\n",
    "6. Setting up docker networks to communicate between containers: https://docs.docker.com/engine/reference/commandline/network_create/\n",
    "7. Setting up to run Docker in a Docker container: https://devopscube.com/run-docker-in-docker/\n",
    "\n",
    "## Overall Design and Architecture\n",
    "My system project is comprised of the following components:\n",
    "* Python code based on the CleanRL project used to execute reinforcement algorithms.\n",
    "* Scripts and Dockerfile for setting up a docker environment in which to run the algorithms.\n",
    "* Hosted WandB running as a Docker container (cloud hosted WandB can easily be used as well by creating an account at no cost).\n",
    "* File system for storing experiment logs, metrics, trained models, and videos.\n",
    "* Tensorboard to visualize runs.\n",
    "\n",
    "All of these work together to allow for an easy way to run experiments and visualize results during training as well as comparing results of experiments after running. The experiment tracking allows multiple experiments to be run simultaneously with the number of experiments run in parallel limited only by the underlying hardware resources. In a cloud environment the experiments are infinitely scalable for all intents and purposes (obviously cloud vendor hardware and the user budget are constraints).\n",
    "\n",
    "## Data Collection and Analysis\n",
    "Since my project was based on reinforcement learning rather than supervised or unsupervised learning I did not need to collect data. I instead evaluated projects to use as the basis for my reinforcement learning environments and chose to focus on OpenAI's gym because it had a good range of projects that could be used for training reinforcement learning algorithms in reasonable times.\n",
    "\n",
    "I saved off all of the data captured as part of the experiments in a way that allows users to effectively analyze algorithms as well as tune hyperparameters and even code changes between experiments.\n",
    "\n",
    "## Model(s) Selection\n",
    "As a platform as a service my project does not involve choosing a model. However it can be utilized by end users in a way to directly make their model selection choice. A user can set up experiments to run the same training procedure on as many different models as they like and at the end of the experiments make a choice for their best model (similar to what I showed for my first use case example demo). My project will capture multiple metrics to aid in this choice including the end performance of the algorithm as well as the overall experiment training time which are the two most likely factors in choosing a model.\n",
    "\n",
    "## Code Design\n",
    "Most of the Python code used for my project was adapted from the CleanRL project which implemented the various machine learning algorithms. One of the core tenets of the CleanRL project is for the code to *NOT* be modular so that people new to the algorithms can see the entire algorithm in just a single file. I adapted their code to make it more modular. I also added cross-cutting functionality for checkpointing models, resuming previous training runs, and testing out stochastic behavior where chosen actions are replaced by random actions a percentage of the time.\n",
    "\n",
    "<a id=\"findings\"></a>\n",
    "## Analysis/Findings\n",
    "Sorry this section may be a little bit long. I'll start with my going in goals.\n",
    "\n",
    "### Goals\n",
    "1. Understand how to use the OpenAI Gym to train against several environments including Atari games.\n",
    "2. Create an environment to track experiments.\n",
    "3. Resume training from a stopped or crashed run.\n",
    "\n",
    "I achieved all three of my goals and so the project was a big win for me personally. I am ready to make use of my project for any reinforcement learning in the future.\n",
    "\n",
    "### OpenAI Gym\n",
    "The OpenAI gym is now supported by another group (Farama foundation): https://github.com/Farama-Foundation/Gymnasium. In addition to supporting Atari environments it supports several others. I tested out both simple classic control environments like CartPole as well as some of the Atari games, mostly Pong and Breakout. Trying out other environment types is an obvious next step and would work seamlessly with my platform, just one more library to install with pip. \n",
    "\n",
    "### Weights and Biases\n",
    "Going in I assumed I would need to build something custom to track experiments. When I came across the Weights and Biases project I quickly realized it already did everything I was looking to do. I will definitely use the project in the future.\n",
    "\n",
    "The one issue I had with the project is that with the self-hosted version I lost my experiments one time, and a second time it seems to have become corrupted to the point I could not recover. I could not find much in the way of bug reports (the project is really new), so at this point I would recommend to only use their cloud hosted version.\n",
    "\n",
    "### Training times\n",
    "I was excited to see how quickly I could train the various algorithms in the different environments. I had planned on trying to train against as many Atari games as I could. It turned out that I only was able to test training with Pong and Breakout. I tried a few algorithms and trained in a few different ways, but in each of the games I needed to train for more than 24 hours to get any kind of reasonable performance. My trained model still lost to the computer player in pong on average at 28 hours, but at least it did win some matches and the average loss was under 4 points as opposed to 21 points at the beginning of training.\n",
    "\n",
    "#### Mac OS with M1 chip\n",
    "Unfortunately most of the training libraries I looked at only provide significant performance improvements when using an NVIDIA GPU. For example when using envpool Pong can be trained in just 10 minutes! However envpool is supported on Linux. I would assume in the coming years more libraries will target adding support for the ML cores on the new Mac chips, but in the meantime I think I need to invest in a Linux desktop with a powerful GPU. The performance difference is too compelling at this point in time.\n",
    "\n",
    "#### Docker\n",
    "When training on docker for I found that performance drastically dropped. For both Pong and Breakout I was averaging only 1 sample per second when compared to roughly 200 second when running on my host. I tried a few configuration changes and settings, but could not improve the performance. I'm not entirely sure whether it is only an issue with Docker for Desktop for Mac. I have seen that on Linux you can allocate host hardware resources successfully with Docker. In any case this was the most disappointing findings for me because I do like using Docker when possible rather than installing directly to my host.\n",
    "\n",
    "#### Reinforcement Learning Algorithms\n",
    "I learned that there were several other reinforcement algorithms beyond just Q-Learning and Sarsa. The CleanRL documentation was great for discovering the algorithms as well as detailed code and documentation on how the algorithms work.\n",
    "\n",
    "## Jupyter Notebook documentation\n",
    "We are reading it now!\n",
    "\n",
    "## Github and Docker Repository\n",
    "The code is all available in Github and in Docker hub. I ensured that the images use the Linux platform rather than the ARM architecture for Mac OS. There are READMEs in both locations to help get started."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451667a1",
   "metadata": {},
   "source": [
    "<a id=\"6ds-framework\"></a>\n",
    "## 6Ds Framework\n",
    "\n",
    "For another overview of the project it is useful to look at it through the 6D framework. Note that since my project is a platform trying to directly map to the 6D framework in some cases it makes more sense to look at how a use case utilizing the platform can apply the 6D framework.\n",
    "\n",
    "### Decomposition\n",
    "The purpose of the platform is to speed up the process of setting up, performing, and analyzing a series of reinforcement learning experiments. By speeding up the process around experimentation, users will be able to achieve their own goals which might fall in the 'reduce workload', 'speed up process', or 'achieve new insight' realm.\n",
    "\n",
    "### Domain Expertise\n",
    "There are a few relevant domains for my project:\n",
    "* Reinforcement Learning\n",
    "* Platform as a Service\n",
    "* Atari games\n",
    "\n",
    "#### Reinforcement Learning\n",
    "For the reinforcement learning aspect I learned quite a bit while performing research and experimentation for my research paper. I am still a novice though and so I spent a good bit of time reading through the algorithms implemented by CleanRL.\n",
    "\n",
    "#### Platform as a Service\n",
    "I have some experience building out a platform as a service on top of AWS and almost 20 years of software development exerience. While I had no experience with many of the tools outside of some Docker experience, I could at least apply related experience to have better insights on what to focus on. \n",
    "\n",
    "#### Atari games\n",
    "Atari games are simple and I have experience playing some of them, so I had an advantage by choosing to test out my platform with atari games as opposed to another realm on which I was not familiar.\n",
    "\n",
    "### Data\n",
    "Since I am focused on a platform and reinforcement learning my project did not rely on collecting data and all of the concerns there such as getting labeled data, making sure the collection was ethical, and minimizing bias. The data concerns for my project were all on the output side. For this I focused more on the design of capturing the data from experiments in a way that was most useful for users of the platform.\n",
    "\n",
    "### Design\n",
    "The platform design is to support experiment training for a broad range of use cases. I provided immediate support for running the CleanRL algorithms against environments in the OpenAI gym, but made it simple to add other environments and other ways to integrate different agents while still being able to track experiments, checkpoint the models, and resume training using Weights and Biases.\n",
    "\n",
    "### Diagnosis\n",
    "The most important part of my system project was providing an environment where end users could analyze their experiments. Some of the key components to help diagnose experiments include:\n",
    "* Visualization of key training information (many charts shown using both WandB and tensorboard)\n",
    "  - Training performance over time\n",
    "  - Number of steps and episodes to achieve certain performance\n",
    "* Visualization of games at various points in training (video display)\n",
    "* Capture of all hyperparameters for an experiment for repeatability and tweaking for future experiments\n",
    "* Easily comparing metrics for multiple experiments\n",
    "\n",
    "### Deployment\n",
    "I wanted deployment of my platform to be as flexible as possible in order to support many use cases. Some of the key features I focused on for deployment were:\n",
    "* Run locally on Mac OS\n",
    "* Run locally on Linux\n",
    "* Run using Docker containers on either Linux or Mac OS\n",
    "* Possibility to run in the cloud\n",
    "\n",
    "Note that I did not test out cloud deployment due to cost concerns as well as not having the time to set things up. I did investigate and found Terraform projects for hosting WandB on each of the major cloud platforms. Each platform also has ways to run docker containers (ECS and EKS in AWS, Cloud run in Google cloud, and Azure container instances in Azure). That would be a logical next future step for this project."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
